{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\NILESH\\Desktop\\IMDB Dataset.csv\")\n",
    "\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  one of the other reviewers has mentioned that ...  \n",
      "1  a wonderful little production br br the filmin...  \n",
      "2  i thought this was a wonderful way to spend ti...  \n",
      "3  basically theres a family where a little boy j...  \n",
      "4  petter matteis love in the time of money is a ...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'\\d+', '', text)  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  \n",
    "    return text\n",
    "\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "print(df[['review', 'cleaned_review']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NILESH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cleaned_review  \\\n",
      "0  one of the other reviewers has mentioned that ...   \n",
      "1  a wonderful little production br br the filmin...   \n",
      "2  i thought this was a wonderful way to spend ti...   \n",
      "3  basically theres a family where a little boy j...   \n",
      "4  petter matteis love in the time of money is a ...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [one, of, the, other, reviewers, has, mentione...  \n",
      "1  [a, wonderful, little, production, br, br, the...  \n",
      "2  [i, thought, this, was, a, wonderful, way, to,...  \n",
      "3  [basically, theres, a, family, where, a, littl...  \n",
      "4  [petter, matteis, love, in, the, time, of, mon...  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['tokens'] = df['cleaned_review'].apply(word_tokenize)\n",
    "print(df[['cleaned_review', 'tokens']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NILESH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cleaned_review  \\\n",
      "0  one of the other reviewers has mentioned that ...   \n",
      "1  a wonderful little production br br the filmin...   \n",
      "2  i thought this was a wonderful way to spend ti...   \n",
      "3  basically theres a family where a little boy j...   \n",
      "4  petter matteis love in the time of money is a ...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [one, reviewers, mentioned, watching, oz, epis...  \n",
      "1  [wonderful, little, production, br, br, filmin...  \n",
      "2  [thought, wonderful, way, spend, time, hot, su...  \n",
      "3  [basically, theres, family, little, boy, jake,...  \n",
      "4  [petter, matteis, love, time, money, visually,...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "print(df[['cleaned_review', 'tokens']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\NILESH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\NILESH\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cleaned_review  \\\n",
      "0  one of the other reviewers has mentioned that ...   \n",
      "1  a wonderful little production br br the filmin...   \n",
      "2  i thought this was a wonderful way to spend ti...   \n",
      "3  basically theres a family where a little boy j...   \n",
      "4  petter matteis love in the time of money is a ...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [one, reviewer, mentioned, watching, oz, episo...  \n",
      "1  [wonderful, little, production, br, br, filmin...  \n",
      "2  [thought, wonderful, way, spend, time, hot, su...  \n",
      "3  [basically, there, family, little, boy, jake, ...  \n",
      "4  [petter, matteis, love, time, money, visually,...  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x] if isinstance(x, list) else [])\n",
    "\n",
    "print(df[['cleaned_review', 'tokens']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      processed_text  \n",
      "0  one reviewer mentioned watching oz episode you...  \n",
      "1  wonderful little production br br filming tech...  \n",
      "2  thought wonderful way spend time hot summer we...  \n",
      "3  basically there family little boy jake think t...  \n",
      "4  petter matteis love time money visually stunni...  \n"
     ]
    }
   ],
   "source": [
    "df['processed_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "print(df[['review', 'processed_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('cleaned_imdb_reviews.csv', index=False)\n",
    "print(\"Cleaned dataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acting' 'amazing' 'amazing story' 'and' 'and great' 'fantastic' 'film'\n",
      " 'great' 'great acting' 'hated' 'hated this' 'is' 'is fantastic' 'movie'\n",
      " 'movie is' 'story' 'story and' 'this' 'this film' 'this movie']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\"This movie is fantastic\", \"I hated this film\", \"Amazing story and great acting\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))  \n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "vector = word2vec_model[\"amazing\"]\n",
    "print(vector.shape) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
